{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826393af-eac5-4c05-a038-90b39e17f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated detection time: 76.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1716178073.963938    1255 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1716178074.085730    1255 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# mediapipeの初期化\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode = True, min_detection_confidence = 0.6, model_complexity = 2)\n",
    "\n",
    "# 姿勢推定を行うファイルを指定\n",
    "file_name = 'test_shiki_short'\n",
    "file_extention = 'mp4'\n",
    "\n",
    "# 姿勢推定を行うファイルを取得\n",
    "cap = cv2.VideoCapture(f'test_data/{file_name}.{file_extention}')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 解析結果の出力先を作成\n",
    "dt_now = datetime.datetime.now()\n",
    "now_time = dt_now.strftime('%y_%m_%d_%H_%M_%S')\n",
    "\n",
    "output_dir = f'test_data/output/template/{file_name}_{now_time}'\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_csv_dir = f'{output_dir}/csv'\n",
    "if not os.path.isdir(output_csv_dir):\n",
    "    os.makedirs(output_csv_dir)\n",
    "\n",
    "# writerの初期化\n",
    "writer = cv2.VideoWriter(f'{output_dir}/output_{file_name}.mp4', cv2.VideoWriter_fourcc(*'mp4v',), fps, frameSize = (int(width), int(height)))\n",
    "\n",
    "# ランドマークのラベル定義\n",
    "landmark_labels = {\n",
    "    'nose': 0,\n",
    "    'left_eye_inner': 1,\n",
    "    'left_eye': 2,\n",
    "    'left_eye_outer': 3,\n",
    "    'right_eye_inner': 4,\n",
    "    'right_eye': 5,\n",
    "    'right_eye_outer': 6,\n",
    "    'left_ear': 7,\n",
    "    'right_ear': 8,\n",
    "    'mouth_left': 9,\n",
    "    'mouth_right': 10,\n",
    "    'left_shoulder': 11,\n",
    "    'right_shoulder': 12,\n",
    "    'left_elbow': 13,\n",
    "    'right_elbow': 14,\n",
    "    'left_wrist': 15,\n",
    "    'right_wrist': 16,\n",
    "    'left_pinky': 17,\n",
    "    'right_pinky': 18,\n",
    "    'left_index': 19,\n",
    "    'right_index': 20,\n",
    "    'left_thumb': 21,\n",
    "    'right_thumb': 22,\n",
    "    'left_hip': 23,\n",
    "    'right_hip': 24,\n",
    "    'left_knee': 25,\n",
    "    'right_knee': 26,\n",
    "    'left_ankle': 27,\n",
    "    'right_ankle': 28,\n",
    "    'left_heel': 29,\n",
    "    'right_heel': 30,\n",
    "    'left_foot_index': 31,\n",
    "    'right_foot_index': 32\n",
    "}\n",
    "\n",
    "# 重要なランドマークのラベル番号\n",
    "important_landmarks = [11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27 ,28]\n",
    "\n",
    "# ランドマークの名前を取得\n",
    "important_landmark_names = [name for name, idx in landmark_labels.items() if idx in important_landmarks]\n",
    "\n",
    "# ランドマークごとに配列を初期化\n",
    "landmarks_data = {label: [] for label in landmark_labels.values()}\n",
    "\n",
    "# ランドマークの総合評価用の配列を初期化\n",
    "# 出力先\n",
    "frame_visibility_csv = f'{output_csv_dir}/frame_important_visibility.csv'\n",
    "header = ['Frame'] + important_landmark_names + ['Visibility over 0.8 count', 'Visibility over 0.8 ratio']\n",
    "frame_visibility_data = []\n",
    "visibility_total = 0\n",
    "\n",
    "all_visibility_csv = f'{output_csv_dir}/frame_all_visibility.csv'\n",
    "all_header = ['Frame'] + list(landmark_labels.keys()) + ['Visibility over 0.8 count', 'Visibility over 0.8 ratio']\n",
    "all_frame_visibility_data = []\n",
    "all_visibility_total = 0\n",
    "\n",
    "# ランドマークごとに配列を初期化\n",
    "landmarks_visibility_data = {label: [] for label in landmark_labels.keys()}\n",
    "\n",
    "# 処理時間の合計を保持する変数を初期化\n",
    "total_processing_time = 0\n",
    "total_pose_detection_time = 0\n",
    "total_pose_drawing_time = 0\n",
    "\n",
    "# 画像の出力先フォルダを初期化\n",
    "# オリジナルデータ\n",
    "output_original_dir = f'{output_dir}/original'\n",
    "if not os.path.isdir(output_original_dir):\n",
    "    os.makedirs(output_original_dir)\n",
    "\n",
    "# 解析データ\n",
    "# 成功データ\n",
    "output_success_dir = f'{output_dir}/processed_image/success'\n",
    "if not os.path.isdir(output_success_dir):\n",
    "    os.makedirs(output_success_dir)\n",
    "\n",
    "# 失敗データ\n",
    "output_failure_dir = f'{output_dir}/processed_image/failure'\n",
    "if not os.path.isdir(output_failure_dir):\n",
    "    os.makedirs(output_failure_dir)\n",
    "\n",
    "# 姿勢推定処理開始\n",
    "if cap.isOpened():\n",
    "    print(f'Estimated detection time: {count * 0.5}s')\n",
    "    num = 1\n",
    "    success_count = 0\n",
    "    min_landmark_detection_rate = 1.0\n",
    "    while cap.isOpened():\n",
    "        if num > count:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            # 元画像の保存\n",
    "            cv2.imwrite(f'{output_original_dir}/{file_name}_{num}.jpg', frame.copy())\n",
    "            output_img = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 姿勢推定処理\n",
    "            pose_start = time.time()\n",
    "            pose_results = pose.process(output_img)\n",
    "            pose_end = time.time()\n",
    "            total_pose_detection_time += (pose_end - pose_start)\n",
    "\n",
    "            # フレームNo.の印字\n",
    "            position = (int(width - 150), int(height - 10))\n",
    "            cv2.putText(output_img, f'Frame: {num}', position, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            # 姿勢推定の描画\n",
    "            drawing_start = time.time()\n",
    "            mp_drawing.draw_landmarks(output_img, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS,)\n",
    "            drawing_end = time.time()\n",
    "            total_pose_drawing_time += (drawing_end - drawing_start)\n",
    "\n",
    "            visibility_data = [num]\n",
    "            visibility_count = 0\n",
    "            all_visibility_data = [num]\n",
    "            all_visibility_count = 0\n",
    "\n",
    "            # 合否判定\n",
    "            if pose_results.pose_world_landmarks:\n",
    "                # 推定成功画像の保存\n",
    "                img_path = f'{output_success_dir}/{file_name}_{num}.jpg'\n",
    "                cv2.imwrite(img_path, cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                # 推定結果の保存\n",
    "                for lm_idx, lm in enumerate(pose_results.pose_world_landmarks.landmark):\n",
    "                    landmarks_data[lm_idx].append([num, (lm.x + 1) * width, (lm.y + 1) * height, lm.z, lm.visibility])\n",
    "                    all_visibility_data.append(lm.visibility)\n",
    "                    landmarks_visibility_data[list(landmark_labels.keys())[lm_idx]].append(lm.visibility)\n",
    "                    if lm.visibility > 0.8:\n",
    "                        all_visibility_count += 1\n",
    "                    if lm_idx in important_landmarks:\n",
    "                        visibility_data.append(lm.visibility)\n",
    "                        if lm.visibility > 0.8:\n",
    "                            visibility_count += 1\n",
    "\n",
    "                #print(f'frame: {num}/{int(count)} success')\n",
    "\n",
    "                success_count += 1\n",
    "\n",
    "            else:\n",
    "                # 推定失敗画像の保存\n",
    "                img_path = f'{output_failure_dir}/{file_name}_{num}.jpg'\n",
    "                cv2.imwrite(img_path, output_img)\n",
    "\n",
    "                # 推定結果の保存\n",
    "                for lm_idx in range(33):\n",
    "                    landmarks_data[lm_idx].append([num, 'null', 'null', 'null', 'null'])\n",
    "                    all_visibility_data.append(0.0)\n",
    "                    if lm_idx in important_landmarks:\n",
    "                        visibility_data.append(0.0)\n",
    "\n",
    "                #print(f'frame: {num}/{int(count)} failure')\n",
    "\n",
    "            visibility_over_count = f'{visibility_count} / {len(important_landmarks)}'\n",
    "            visibility_data.append(visibility_over_count)\n",
    "            visibility_over_ratio = visibility_count / len(important_landmarks)\n",
    "            visibility_data.append(visibility_over_ratio)\n",
    "            visibility_total += visibility_over_ratio\n",
    "\n",
    "            all_visibility_over_count = f'{all_visibility_count} / {len(landmark_labels)}'\n",
    "            all_visibility_data.append(visibility_over_count)\n",
    "            all_visibility_over_ratio = all_visibility_count / len(landmark_labels)\n",
    "            all_visibility_data.append(all_visibility_over_ratio)\n",
    "            all_visibility_total += all_visibility_over_ratio\n",
    "\n",
    "            frame_visibility_data.append(visibility_data)\n",
    "            all_frame_visibility_data.append(all_visibility_data)\n",
    "\n",
    "            # 解析画像を動画に記録\n",
    "            writer.write(cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_processing_time += (end_time - start_time)\n",
    "        num += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    print(f'Actual detection time: {total_processing_time}s')\n",
    "\n",
    "    # 各平均時間の算出\n",
    "    avg_processing_time = total_processing_time/ (num - 1)\n",
    "    avg_pose_detection_time = total_pose_detection_time / (num - 1)\n",
    "    avg_pose_drawing_time = total_pose_drawing_time / (num - 1)\n",
    "    avg_visibility = visibility_total / (num - 1)\n",
    "    avg_all_visibility = all_visibility_total / (num - 1)\n",
    "\n",
    "    text_lines = [\n",
    "        f'トータル処理時間： {total_processing_time}\\n',\n",
    "        f'Video Width： {width}\\n',\n",
    "        f'Video Height： {height}\\n',\n",
    "        f'Video Frame Count： {count}\\n',\n",
    "        f'Video FPS： {fps}\\n',\n",
    "        f'Video Time： {count/fps}\\n\\n'\n",
    "        f'平均処理時間： {avg_processing_time}\\n',\n",
    "        f'平均姿勢推定処理時間： {avg_pose_detection_time}\\n',\n",
    "        f'平均姿勢推定描画時間： {avg_pose_drawing_time}\\n',\n",
    "        f'平均ランドマーク検出確率(All)： {avg_visibility}\\n',\n",
    "        f'平均ランドマーク検出確率(Important)： {avg_all_visibility}\\n'\n",
    "    ]\n",
    "\n",
    "    # 解析結果の記録\n",
    "    with open(f'{output_dir}/result.txt', mode = 'w', encoding = 'utf-8', newline = '\\n') as f:\n",
    "        f.writelines(text_lines)\n",
    "\n",
    "    # 解析結果のCSVの作成\n",
    "    for label_idx, lm_data in landmarks_data.items():\n",
    "        lm_name = [name for name, idx in landmark_labels.items() if idx == label_idx][0]\n",
    "        csv_file_path = f'{output_csv_dir}/landmark_{label_idx}_{lm_name}.csv'\n",
    "        with open(csv_file_path, mode = 'w', newline = '') as file:\n",
    "            csv_writer = csv.writer(file)\n",
    "            csv_writer.writerow(['frame num', 'x', 'y', 'z', 'visibility'])\n",
    "            csv_writer.writerows(lm_data)\n",
    "        #print(f'Saved {csv_file_path}')\n",
    "\n",
    "    avg_landmark_visibility = ['average']\n",
    "    max_landmark_visibility = ['maximum']\n",
    "    min_landmark_visibility = ['minimum']\n",
    "\n",
    "    for i in len(landmark_labels):\n",
    "        data = landmarks_visibility_data[list(landmark_labels.keys())[i]]\n",
    "        avg_landmark_visibility.append(sum(data)/len(data))\n",
    "        max_landmark_visibility.append(max(data))\n",
    "        min_landmark_visibility.append(min(data))\n",
    "\n",
    "    with open(frame_visibility_csv, mode = 'w', newline = '') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        csv_writer.writerow(header)\n",
    "        csv_writer.writerows(frame_visibility_data)\n",
    "        csv_writer.writerow(avg_landmark_visibility)\n",
    "        csv_writer.writerow(max_landmark_visibility)\n",
    "        csv_writer.writerow(min_landmark_visibility)\n",
    "\n",
    "    with open(all_visibility_csv, mode = 'w', newline = '') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        csv_writer.writerow(all_header)\n",
    "        csv_writer.writerows(all_frame_visibility_data)\n",
    "\n",
    "else:\n",
    "    print('Cannot Opened File')\n",
    "\n",
    "print('Detection Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce0fbd-bbd8-4bd3-8280-2196b483a605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
